{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "god-idclass.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hailusong/colab-god-idclass/blob/master/god_idclass.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "TjlYaLbjqZ8T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Custom Train Google Object Detection to Detect ID BBox"
      ]
    },
    {
      "metadata": {
        "id": "2R9EiJRx7bMQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Environment variables setup.<br>\n",
        "**Tensorflow runtime version list** can be found at [here](https://cloud.google.com/ml-engine/docs/tensorflow/runtime-version-list)"
      ]
    },
    {
      "metadata": {
        "id": "P6Xb78JiIUaY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "DEFAULT_HOME='/content'\n",
        "TF_RT_VERSION='1.13'\n",
        "PYTHON_VERSION='3.5'\n",
        "\n",
        "YOUR_GCS_BUCKET='id-norm'\n",
        "YOUR_PROJECT='orbital-purpose-130316'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0bAXZIZvDcv8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Session and Environment Verification (Destination - Local)"
      ]
    },
    {
      "metadata": {
        "id": "ogk6pbZ_DAYc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Establish security session with Google Cloud"
      ]
    },
    {
      "metadata": {
        "id": "JuDI1KX7rRpq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L2u7WXAwd8Si",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "################# RE-RUN ABOVE CELLS IF NEED TO RESTART RUNTIME #################"
      ]
    },
    {
      "metadata": {
        "id": "1mU8k4b2DZ8C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Verify Versions: TF, Python, IPython and prompt_toolkit (these two need to have compatible version), and protoc"
      ]
    },
    {
      "metadata": {
        "id": "p8pW_0h7r4L5",
        "colab_type": "code",
        "outputId": "6178d466-8311-4269-eba8-662f270ccf4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "assert(tf.__version__.startswith(TF_RT_VERSION + '.')), f'tf.__version__ {tf.__version__} not matching with specified TF runtime version env variable {TF_RT_VERSION}'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.13.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "d-WRNGIpFfo-",
        "colab_type": "code",
        "outputId": "eb0725c6-feea-40a5-a09a-e9e6ed1e3ebe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "!python -V\n",
        "!ipython --version\n",
        "!pip show prompt_toolkit\n",
        "!protoc --version"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.6.7\n",
            "5.5.0\n",
            "Name: prompt-toolkit\n",
            "Version: 1.0.15\n",
            "Summary: Library for building powerful interactive command lines in Python\n",
            "Home-page: https://github.com/jonathanslenders/python-prompt-toolkit\n",
            "Author: Jonathan Slenders\n",
            "Author-email: UNKNOWN\n",
            "License: UNKNOWN\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: six, wcwidth\n",
            "Required-by: jupyter-console, ipython\n",
            "libprotoc 3.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "omvtVm1tEXTk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Install Google Object Detection API in Colab\n",
        "Reference is https://colab.research.google.com/drive/1kHEQK2uk35xXZ_bzMUgLkoysJIWwznYr\n"
      ]
    },
    {
      "metadata": {
        "id": "V2S37bciJ0rW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Downgrade prompt-toolkit to 1.0.15 (Destination - Local)\n",
        "Run this **ONLY** if the Installation not Working"
      ]
    },
    {
      "metadata": {
        "id": "x0dlIgSUJ19q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install 'prompt-toolkit==1.0.15'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wsjTyacRJ-ji",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Google Object Detection API Installation (Destination - Local)"
      ]
    },
    {
      "metadata": {
        "id": "V8sD3HbnEhq1",
        "colab_type": "code",
        "outputId": "5c5dbace-d2e5-480f-f32a-ecabfecb9e98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq protobuf-compiler python-pil python-lxml\n",
        "![ ! -e {DEFAULT_HOME}/models ] && git clone --depth=1 --quiet https://github.com/tensorflow/models.git {DEFAULT_HOME}/models\n",
        "!ls {DEFAULT_HOME}/models"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUTHORS     CONTRIBUTING.md    LICENSE\t README.md  samples    WORKSPACE\n",
            "CODEOWNERS  ISSUE_TEMPLATE.md  official  research   tutorials\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Lrcxm-rnEpEJ",
        "colab_type": "code",
        "outputId": "3a288834-93d3-4270-dad2-24d5ac2860a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(f'{DEFAULT_HOME}/models/research')\n",
        "!pwd"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "z8_fKK8SGX4k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*From Wikipedia ...*: \n",
        "\n",
        "**protocol buffers** are a language-neutral, platform-neutral extensible mechanism for serializing structured data â€“ think XML, but smaller, faster, and simpler. \n",
        "\n",
        "You define how you want your data to be structured once, then you can **use special generated source code to easily write and read your structured data to and from a variety of data streams and using a variety of languages**.\n",
        "\n",
        "Remember **.proto defines structured data** and **protoc generates the source code** the serailize/de-serialize."
      ]
    },
    {
      "metadata": {
        "id": "k77QnbWPEuUU",
        "colab_type": "code",
        "outputId": "7693e47d-a8f8-4d17-d8d9-2a26176b60eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "# !ls object_detection/protos/*.proto\n",
        "# !cat object_detection/protos/anchor_generator.proto\n",
        "!ls {DEFAULT_HOME}/models/research/object_detection/builders/anchor*"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research/object_detection/builders/anchor_generator_builder.py\n",
            "/content/models/research/object_detection/builders/anchor_generator_builder_test.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "muV6amLl4Bya",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Add Google Object Detection API into System Path"
      ]
    },
    {
      "metadata": {
        "id": "RS2Aj9YEEv5_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(f'{DEFAULT_HOME}/models/research')\n",
        "sys.path.append(f'{DEFAULT_HOME}/models/research/slim')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LbDcBTuIXwBZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Note that ! calls out to a shell (in a **NEW** process), while % affects the **SAME** process associated with the notebook.\n",
        "\n",
        "Since we append pathes to sys.path, we **HAVE TO** use % command to run the Python\n",
        "\n",
        "Also it is **IMPORTANT** to have **%matplotlib inline** otherwise %run model_builder_test.py will **cause function attribute error** when accessing matplotlib.pyplot attributes from **iPython's run_line_magic** "
      ]
    },
    {
      "metadata": {
        "id": "KrYcIPx7XPHG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !find . -name 'inception*' -print\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ccpkEmORExv-",
        "colab_type": "code",
        "outputId": "838284d1-7000-4b30-936b-31c8cb5a9788",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "# If see the error 'function' object has no attribute 'called', just run the %matplotlib cell and this cell AGAIN \n",
        "%run object_detection/builders/model_builder_test.py\n",
        "\n",
        "import os\n",
        "os.chdir(f'{DEFAULT_HOME}')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "............s...\n",
            "----------------------------------------------------------------------\n",
            "Ran 16 tests in 0.154s\n",
            "\n",
            "OK (skipped=1)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "QGWzWonShuRj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Pre-trained Data Prepatation (Destination - GCS)\n",
        "e.g. pre-trained model weights"
      ]
    },
    {
      "metadata": {
        "id": "H-fWjtKBifOD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Download, unzip and move COCO-pretrained weights data to GCS<br>\n",
        "Other possible pretrained models:<br>\n",
        "* ssd_mobilenet_v1_coco_11_06_2017\n",
        "* ssd_inception_v2_coco_11_06_2017\n",
        "* rfcn_resnet101_coco_11_06_2017\n",
        "* faster_rcnn_resnet101_coco_11_06_2017\n",
        "* faster_rcnn_inception_resnet_v2_atrous_coco_11_06_2017"
      ]
    },
    {
      "metadata": {
        "id": "4lVOv3a3FG6i",
        "colab_type": "code",
        "outputId": "bb162250-235e-4963-ee58-90a40d8d6f1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(f'{DEFAULT_HOME}')\n",
        "!wget http://storage.googleapis.com/download.tensorflow.org/models/object_detection/faster_rcnn_resnet101_coco_11_06_2017.tar.gz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-03-19 14:19:45--  http://storage.googleapis.com/download.tensorflow.org/models/object_detection/faster_rcnn_resnet101_coco_11_06_2017.tar.gz\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.141.128, 2607:f8b0:400c:c06::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.141.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 595490113 (568M) [application/x-tar]\n",
            "Saving to: â€˜faster_rcnn_resnet101_coco_11_06_2017.tar.gzâ€™\n",
            "\n",
            "faster_rcnn_resnet1 100%[===================>] 567.90M   156MB/s    in 3.6s    \n",
            "\n",
            "2019-03-19 14:19:49 (156 MB/s) - â€˜faster_rcnn_resnet101_coco_11_06_2017.tar.gzâ€™ saved [595490113/595490113]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7ektZ4KTN_sa",
        "colab_type": "code",
        "outputId": "b1cdf10f-5dbc-462d-cfd1-c291a4b78dcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "!ls {DEFAULT_HOME}/faster_rcnn_resnet101_coco_11_06_2017"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "frozen_inference_graph.pb  model.ckpt.data-00000-of-00001  model.ckpt.meta\n",
            "graph.pbtxt\t\t   model.ckpt.index\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "M2XJoiNJii2s",
        "colab_type": "code",
        "outputId": "5959eb01-5fc5-43b0-e249-9432b77d6cd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "cell_type": "code",
      "source": [
        "![ ! -e faster_rcnn_resnet101_coco_11_06_2017 ] && tar -xvf faster_rcnn_resnet101_coco_11_06_2017.tar.gz\n",
        "!gsutil cp faster_rcnn_resnet101_coco_11_06_2017/model.ckpt.* gs://{YOUR_GCS_BUCKET}/data/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "faster_rcnn_resnet101_coco_11_06_2017/\n",
            "faster_rcnn_resnet101_coco_11_06_2017/model.ckpt.index\n",
            "faster_rcnn_resnet101_coco_11_06_2017/model.ckpt.meta\n",
            "faster_rcnn_resnet101_coco_11_06_2017/frozen_inference_graph.pb\n",
            "faster_rcnn_resnet101_coco_11_06_2017/model.ckpt.data-00000-of-00001\n",
            "faster_rcnn_resnet101_coco_11_06_2017/graph.pbtxt\n",
            "Copying file://faster_rcnn_resnet101_coco_11_06_2017/model.ckpt.data-00000-of-00001 [Content-Type=application/octet-stream]...\n",
            "==> NOTE: You are uploading one or more large file(s), which would run\n",
            "significantly faster if you enable parallel composite uploads. This\n",
            "feature can be enabled by editing the\n",
            "\"parallel_composite_upload_threshold\" value in your .boto\n",
            "configuration file. However, note that if you do this large files will\n",
            "be uploaded as `composite objects\n",
            "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
            "means that any user who downloads such objects will need to have a\n",
            "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
            "without a compiled crcmod, computing checksums on composite objects is\n",
            "so slow that gsutil disables downloads of composite objects.\n",
            "\n",
            "Copying file://faster_rcnn_resnet101_coco_11_06_2017/model.ckpt.index [Content-Type=application/octet-stream]...\n",
            "Copying file://faster_rcnn_resnet101_coco_11_06_2017/model.ckpt.meta [Content-Type=application/octet-stream]...\n",
            "/\n",
            "Operation completed over 3 objects/435.9 MiB.                                    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aCJUcq6XbZo5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Configuring the Object Detection Pipeline (Destination - GCS)"
      ]
    },
    {
      "metadata": {
        "id": "IiqAkpnYbbBm",
        "colab_type": "code",
        "outputId": "f49356b9-4abc-4223-e0ea-aec0b1e5fcac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "![ -e {DEFAULT_HOME}/colab-god-idclass ] && git -C {DEFAULT_HOME}/colab-god-idclass pull\n",
        "![ ! -e {DEFAULT_HOME}/colab-god-idclass ] && git clone --depth=1 https://github.com/hailusong/colab-god-idclass.git {DEFAULT_HOME}/colab-god-idclass"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into '/content/colab-god-idclass'...\n",
            "remote: Enumerating objects: 12, done.\u001b[K\n",
            "remote: Counting objects:   8% (1/12)   \u001b[K\rremote: Counting objects:  16% (2/12)   \u001b[K\rremote: Counting objects:  25% (3/12)   \u001b[K\rremote: Counting objects:  33% (4/12)   \u001b[K\rremote: Counting objects:  41% (5/12)   \u001b[K\rremote: Counting objects:  50% (6/12)   \u001b[K\rremote: Counting objects:  58% (7/12)   \u001b[K\rremote: Counting objects:  66% (8/12)   \u001b[K\rremote: Counting objects:  75% (9/12)   \u001b[K\rremote: Counting objects:  83% (10/12)   \u001b[K\rremote: Counting objects:  91% (11/12)   \u001b[K\rremote: Counting objects: 100% (12/12)   \u001b[K\rremote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects:   9% (1/11)   \u001b[K\rremote: Compressing objects:  18% (2/11)   \u001b[K\rremote: Compressing objects:  27% (3/11)   \u001b[K\rremote: Compressing objects:  36% (4/11)   \u001b[K\rremote: Compressing objects:  45% (5/11)   \u001b[K\rremote: Compressing objects:  54% (6/11)   \u001b[K\rremote: Compressing objects:  63% (7/11)   \u001b[K\rremote: Compressing objects:  72% (8/11)   \u001b[K\rremote: Compressing objects:  81% (9/11)   \u001b[K\rremote: Compressing objects:  90% (10/11)   \u001b[K\rremote: Compressing objects: 100% (11/11)   \u001b[K\rremote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 12 (delta 0), reused 6 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects:   8% (1/12)   \rUnpacking objects:  16% (2/12)   \rUnpacking objects:  25% (3/12)   \rUnpacking objects:  33% (4/12)   \rUnpacking objects:  41% (5/12)   \rUnpacking objects:  50% (6/12)   \rUnpacking objects:  58% (7/12)   \rUnpacking objects:  66% (8/12)   \rUnpacking objects:  75% (9/12)   \rUnpacking objects:  83% (10/12)   \rUnpacking objects:  91% (11/12)   \rUnpacking objects: 100% (12/12)   \rUnpacking objects: 100% (12/12), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GnuR86Zslvlb",
        "colab_type": "code",
        "outputId": "cb20dd30-5f59-4447-d4f5-7479dd712501",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "!ls -al {DEFAULT_HOME}/colab-god-idclass/configs/faster_rcnn_resnet101.config\n",
        "!sed 's/..YOUR_GCS_BUCKET./{YOUR_GCS_BUCKET}/g' < {DEFAULT_HOME}/colab-god-idclass/configs/faster_rcnn_resnet101.config > {DEFAULT_HOME}/colab-god-idclass/configs/faster_rcnn_resnet101_processed.config\n",
        "!gsutil cp {DEFAULT_HOME}/colab-god-idclass/configs/faster_rcnn_resnet101_processed.config \\\n",
        "           {DEFAULT_HOME}/colab-god-idclass/configs/label_map.pbtxt \\\n",
        "           gs://{YOUR_GCS_BUCKET}/data"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 3673 Mar 26 01:46 /content/colab-god-idclass/configs/faster_rcnn_resnet101.config\n",
            "Copying file:///content/colab-god-idclass/configs/faster_rcnn_resnet101_processed.config [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/colab-god-idclass/configs/label_map.pbtxt [Content-Type=application/octet-stream]...\n",
            "/ [2 files][  3.6 KiB/  3.6 KiB]                                                \n",
            "Operation completed over 2 objects/3.6 KiB.                                      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sItSbiqRmyin",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Checking Your Google Cloud Storage Bucket"
      ]
    },
    {
      "metadata": {
        "id": "LIekVw8Nmup6",
        "colab_type": "code",
        "outputId": "3413294a-8ad2-41bc-a5d2-4643d27f5edd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "cell_type": "code",
      "source": [
        "!gsutil ls gs://{YOUR_GCS_BUCKET}/data\n",
        "!gsutil ls gs://{YOUR_GCS_BUCKET}/generated"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gs://id-norm/data/faster_rcnn_resnet101_processed.config\n",
            "gs://id-norm/data/label_map.pbtxt\n",
            "gs://id-norm/data/model.ckpt.data-00000-of-00001\n",
            "gs://id-norm/data/model.ckpt.index\n",
            "gs://id-norm/data/model.ckpt.meta\n",
            "gs://id-norm/data/test.record\n",
            "gs://id-norm/data/train.record\n",
            "CommandException: One or more URLs matched no objects.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rBNDkVabtHLr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Prepare Our Own Data: Download, Convert and Upload (Destination - GCS)"
      ]
    },
    {
      "metadata": {
        "id": "uJoYIAf1DJw_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Use Google Cloud SDK gsutil to download the data file **generated.tar.gz**<br>\n",
        "Note that the file **generated.tar.gz** MUST BE uploaded to GCS bucket by:<br>\n",
        "* Run the BB project idaug to generate images, bbox csv and key-points csv in folder **generated**\n",
        "* Tar/gzip the whole **generated** folder to **generated.tar.gz**"
      ]
    },
    {
      "metadata": {
        "id": "OJbzJ9xpV5Eh",
        "colab_type": "code",
        "outputId": "034d0a0a-02c6-4a43-a7bc-ea3500d1fb16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "# Download the file.\n",
        "!gsutil cp gs://{YOUR_GCS_BUCKET}/generated.tar.gz /tmp/generated.tar.gz\n",
        "!ls /tmp/*gz"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://id-norm/generated.tar.gz...\n",
            "\\ [1 files][131.2 MiB/131.2 MiB]                                                \n",
            "Operation completed over 1 objects/131.2 MiB.                                    \n",
            "/tmp/generated.tar.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dKIsia2KDWtH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Prepare the data file (unzip, untar)"
      ]
    },
    {
      "metadata": {
        "id": "PkllRh0irCyJ",
        "colab_type": "code",
        "outputId": "7f7ff552-74ad-444f-b982-f8cc5b129f69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(f'{DEFAULT_HOME}')\n",
        "\n",
        "![[ ! -f /tmp/generated.tar && -f /tmp/generated.tar.gz ]] && gunzip /tmp/generated.tar.gz\n",
        "![[ ! -e ./generated && -f /tmp/generated.tar ]] && tar xf /tmp/generated.tar\n",
        "!pwd\n",
        "!ls {DEFAULT_HOME}/generated"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "bbox-train-non-id1.csv\tbbox-valid-on-dl.csv\tpnts-valid-non-id2.csv\n",
            "bbox-train-non-id2.csv\tbbox-valid-on-hc.csv\tpnts-valid-non-id3.csv\n",
            "bbox-train-non-id3.csv\tpnts-train-non-id1.csv\tpnts-valid-on-dl.csv\n",
            "bbox-train-on-dl.csv\tpnts-train-non-id2.csv\tpnts-valid-on-hc.csv\n",
            "bbox-train-on-hc.csv\tpnts-train-non-id3.csv\tTrain\n",
            "bbox-valid-non-id1.csv\tpnts-train-on-dl.csv\tValid\n",
            "bbox-valid-non-id2.csv\tpnts-train-on-hc.csv\n",
            "bbox-valid-non-id3.csv\tpnts-valid-non-id1.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "89zLiFemnjWP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Copy unzip generated back\n",
        "!gsutil cp -R {DEFAULT_HOME}/generated gs://{YOUR_GCS_BUCKET}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PZy1La85BwXJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Concat all train csv together, keep only one header and name the first column (no name in the input as it is considered as index column in BB project idaug).<br>\n",
        "Apply the same processing to validation data as well."
      ]
    },
    {
      "metadata": {
        "id": "nez_KOYYIEzx",
        "colab_type": "code",
        "outputId": "099a144e-6d4a-4360-8285-98b8029b51d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "cell_type": "code",
      "source": [
        "!head -1 {DEFAULT_HOME}/generated/bbox-train-on-dl.csv | sed 's/^,/filename,/' > {DEFAULT_HOME}/train-merged.csv\n",
        "!head -1 {DEFAULT_HOME}/generated/bbox-valid-on-dl.csv | sed 's/^,/filename,/' > {DEFAULT_HOME}/valid-merged.csv\n",
        "!tail -q --lines=+2 {DEFAULT_HOME}/generated/bbox-train-*.csv | sed 's/\\\\/\\//g' >> {DEFAULT_HOME}/train-merged.csv\n",
        "!tail -q --lines=+2 {DEFAULT_HOME}/generated/bbox-valid-*.csv | sed 's/\\\\/\\//g' >> {DEFAULT_HOME}/valid-merged.csv\n",
        "!ls {DEFAULT_HOME}/generated\n",
        "!head {DEFAULT_HOME}/train-merged.csv {DEFAULT_HOME}/valid-merged.csv"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bbox-train-non-id1.csv\tbbox-valid-on-dl.csv\tpnts-valid-non-id2.csv\n",
            "bbox-train-non-id2.csv\tbbox-valid-on-hc.csv\tpnts-valid-non-id3.csv\n",
            "bbox-train-non-id3.csv\tpnts-train-non-id1.csv\tpnts-valid-on-dl.csv\n",
            "bbox-train-on-dl.csv\tpnts-train-non-id2.csv\tpnts-valid-on-hc.csv\n",
            "bbox-train-on-hc.csv\tpnts-train-non-id3.csv\tTrain\n",
            "bbox-valid-non-id1.csv\tpnts-train-on-dl.csv\tValid\n",
            "bbox-valid-non-id2.csv\tpnts-train-on-hc.csv\n",
            "bbox-valid-non-id3.csv\tpnts-valid-non-id1.csv\n",
            "==> /content/train-merged.csv <==\n",
            "filename,bbox1_x1,bbox1_y1,bbox1_x2,bbox1_y2,label\n",
            "generated/Train/non-id1/0.png,10,5,143,93,UNKNOWN\n",
            "generated/Train/non-id1/1.png,15,0,126,74,UNKNOWN\n",
            "generated/Train/non-id1/2.png,40,23,119,76,UNKNOWN\n",
            "generated/Train/non-id1/3.png,20,51,246,202,UNKNOWN\n",
            "generated/Train/non-id1/4.png,15,33,129,109,UNKNOWN\n",
            "generated/Train/non-id1/5.png,38,43,114,94,UNKNOWN\n",
            "generated/Train/non-id1/6.png,51,10,223,125,UNKNOWN\n",
            "generated/Train/non-id1/7.png,38,48,198,155,UNKNOWN\n",
            "generated/Train/non-id1/8.png,38,33,255,178,UNKNOWN\n",
            "\n",
            "==> /content/valid-merged.csv <==\n",
            "filename,bbox1_x1,bbox1_y1,bbox1_x2,bbox1_y2,label\n",
            "generated/Valid/non-id1/0.png,7,38,86,91,UNKNOWN\n",
            "generated/Valid/non-id1/1.png,46,12,137,73,UNKNOWN\n",
            "generated/Valid/non-id1/2.png,23,17,252,170,UNKNOWN\n",
            "generated/Valid/non-id1/3.png,51,5,165,81,UNKNOWN\n",
            "generated/Valid/non-id1/4.png,17,0,197,120,UNKNOWN\n",
            "generated/Valid/non-id1/5.png,35,48,237,183,UNKNOWN\n",
            "generated/Valid/non-id1/6.png,34,35,256,183,UNKNOWN\n",
            "generated/Valid/non-id1/7.png,2,33,231,186,UNKNOWN\n",
            "generated/Valid/non-id1/8.png,48,33,174,116,UNKNOWN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "k04XjGpeEN3y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Upload unzip data file to GCS bucket in parallel mode (-m)"
      ]
    },
    {
      "metadata": {
        "id": "2RQc8Ly3Dt1f",
        "colab_type": "code",
        "outputId": "5b448ba5-dd37-4be3-dc50-d7a78d8b307b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "!gsutil cp {DEFAULT_HOME}/train-merged.csv {DEFAULT_HOME}/valid-merged.csv gs://{YOUR_GCS_BUCKET}"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying file:///content/train-merged.csv [Content-Type=text/csv]...\n",
            "Copying file:///content/valid-merged.csv [Content-Type=text/csv]...\n",
            "/ [2 files][ 60.0 KiB/ 60.0 KiB]                                                \n",
            "Operation completed over 2 objects/60.0 KiB.                                     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kZz2pXA9G8OS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Convert Our Label CSV Data to TF REcord\n",
        "Source code is based on https://github.com/datitran/raccoon_dataset/blob/master/generate_tfrecord.py"
      ]
    },
    {
      "metadata": {
        "id": "DWu_rViFfPIf",
        "colab_type": "code",
        "outputId": "df99d0f6-9994-436b-cdba-581e68bffa45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "%pdb"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Automatic pdb calling has been turned ON\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AqJWpCJvv-tD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(f'{DEFAULT_HOME}')\n",
        "\n",
        "!head {DEFAULT_HOME}/train-merged.csv\n",
        "!mkdir -p {DEFAULT_HOME}/coversion\n",
        "!git -C {DEFAULT_HOME}/colab-god-idclass pull\n",
        "\n",
        "# Train records first\n",
        "%run {DEFAULT_HOME}/colab-god-idclass/src/generate_tfrecord.py --csv_input={DEFAULT_HOME}/train-merged.csv --output_path={DEFAULT_HOME}/coversion/train.record"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wZyM8rr_iTY1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Validation records second\n",
        "!head {DEFAULT_HOME}/valid-merged.csv\n",
        "%run {DEFAULT_HOME}/colab-god-idclass/src/generate_tfrecord.py --csv_input={DEFAULT_HOME}/valid-merged.csv --output_path={DEFAULT_HOME}/coversion/test.record"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w612LJWywgl9",
        "colab_type": "code",
        "outputId": "735b77b6-cd84-4be5-ba28-cf6966716f76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "!gsutil cp {DEFAULT_HOME}/coversion/train.record {DEFAULT_HOME}/coversion/test.record gs://{YOUR_GCS_BUCKET}/data"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying file:///content/coversion/train.record [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/coversion/test.record [Content-Type=application/octet-stream]...\n",
            "|\n",
            "Operation completed over 2 objects/131.8 MiB.                                    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GmmS7dXejke0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Start the Training and Evaluation Jobs on Google Cloud ML Engine"
      ]
    },
    {
      "metadata": {
        "id": "k9Jj2W0Ak5rC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Option 1: Start the Training Job on Google Cloud ML (Destination - Cloud ML)"
      ]
    },
    {
      "metadata": {
        "id": "oFy4tt53j4bZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Package the Tensorflow Object Detection code (Destination - Local but to be submitted as package to Cloud ML)\n",
        "Before you can run on GCP, you must first **package the TensorFlow Object Detection API and TF Slim**."
      ]
    },
    {
      "metadata": {
        "id": "KO_5PPACjI0s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(f'{DEFAULT_HOME}/models/research')\n",
        "\n",
        "# From tensorflow/models/research/\n",
        "!bash object_detection/dataset_tools/create_pycocotools_package.sh /tmp/pycocotools\n",
        "!python setup.py sdist\n",
        "!(cd slim && python setup.py sdist)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FBWz59ockMQi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Three python packages will be created:\n",
        "* dist/object_detection-0.1.tar.gz\n",
        "* slim/dist/slim-0.1.tar.gz\n",
        "* /tmp/pycocotools/pycocotools-2.0.tar.gz"
      ]
    },
    {
      "metadata": {
        "id": "m23IkmNbjzYb",
        "colab_type": "code",
        "outputId": "edf451f6-bfb1-4443-9dc0-950e2540878a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "!ls -l dist/object_detection-0.1.tar.gz\n",
        "!ls -l slim/dist/slim-0.1.tar.gz\n",
        "!ls -l /tmp/pycocotools/pycocotools-2.0.tar.gz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 439299460 Mar 23 22:11 dist/object_detection-0.1.tar.gz\n",
            "-rw-r--r-- 1 root root 973963 Mar 23 22:11 slim/dist/slim-0.1.tar.gz\n",
            "-rw-r--r-- 1 root root 1376450 Mar 23 22:10 /tmp/pycocotools/pycocotools-2.0.tar.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EHuJCfKxoLn1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "If you experience 'Permission denied on resource project ...' issue, make sure Cloud ML engine API has been enabled for the project. Use this [link](https://console.cloud.google.com/flows/enableapi?apiid=ml.googleapis.com,compute_component) to check and enable if not yet done."
      ]
    },
    {
      "metadata": {
        "id": "aUo0VrXBkYp9",
        "colab_type": "code",
        "outputId": "7f656465-d54e-4371-d5d4-fdf9bafe9063",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# From tensorflow/models/research/\n",
        "!gcloud config set project {YOUR_PROJECT}"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updated property [core/project].\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YGBTfl7a3p6_",
        "colab_type": "code",
        "outputId": "c9ca845c-2a33-4616-f616-e43a3bd51d4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "!cat object_detection/samples/cloud/cloud.yml"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "trainingInput:\n",
            "  runtimeVersion: \"1.12\"\n",
            "  scaleTier: CUSTOM\n",
            "  masterType: standard_gpu\n",
            "  workerCount: 5\n",
            "  workerType: standard_gpu\n",
            "  parameterServerCount: 3\n",
            "  parameterServerType: standard\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "B-jTSuP20Vy_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " #### Start the Training Job on Google Cloud ML (Destination - Cloud ML)"
      ]
    },
    {
      "metadata": {
        "id": "atuWjEwPv8eP",
        "colab_type": "code",
        "outputId": "81e9c02d-efde-475d-f60e-79634ed4ca0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "!gcloud ml-engine jobs submit training `whoami`_object_detection_ids_`date +%m_%d_%Y_%H_%M_%S` \\\n",
        "    --runtime-version {TF_RT_VERSION} \\\n",
        "    --job-dir=gs://{YOUR_GCS_BUCKET}/model_dir \\\n",
        "    --packages dist/object_detection-0.1.tar.gz,slim/dist/slim-0.1.tar.gz,/tmp/pycocotools/pycocotools-2.0.tar.gz \\\n",
        "    --module-name object_detection.model_main \\\n",
        "    --region us-central1 \\\n",
        "    --config object_detection/samples/cloud/cloud.yml \\\n",
        "    --python-version {PYTHON_VERSION} \\\n",
        "    -- \\\n",
        "    --model_dir=gs://{YOUR_GCS_BUCKET}/model_dir \\\n",
        "    --pipeline_config_path=gs://{YOUR_GCS_BUCKET}/data/faster_rcnn_resnet101_processed.config"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Job [root_object_detection_ids_03_23_2019_22_25_20] submitted successfully.\n",
            "Your job is still active. You may view the status of your job with the command\n",
            "\n",
            "  $ gcloud ml-engine jobs describe root_object_detection_ids_03_23_2019_22_25_20\n",
            "\n",
            "or continue streaming the logs with the command\n",
            "\n",
            "  $ gcloud ml-engine jobs stream-logs root_object_detection_ids_03_23_2019_22_25_20\n",
            "jobId: root_object_detection_ids_03_23_2019_22_25_20\n",
            "state: QUEUED\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JT8RGNNtYibu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Option 2: Start the Training Job on CoLab"
      ]
    },
    {
      "metadata": {
        "id": "AWUM71-lvWuS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Clean up the those tf.app.flags usde by Object Detection API** (so that we don't need to restart the runtime if we want to %run the Google object detection API again in the same session)"
      ]
    },
    {
      "metadata": {
        "id": "T5nHitXclD9n",
        "colab_type": "code",
        "outputId": "c36a070b-6e1d-4cac-bd47-03f922dd692e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "def del_all_flags(FLAGS, excls):\n",
        "    flags_dict = FLAGS._flags()\n",
        "    keys_list = [keys for keys in flags_dict]\n",
        "    for keys in keys_list:\n",
        "        if keys in excls:\n",
        "          print(f'SKIPPING exclusion attribute {keys}')\n",
        "          continue\n",
        "          \n",
        "        print(f'removing attribute {keys}')\n",
        "        FLAGS.__delattr__(keys)\n",
        "\n",
        "\n",
        "# if running inside IPython notebook, the python session will be maintained across\n",
        "# cells, so does the tf.app.flags. That will cause flags defined twice error\n",
        "# if we %run the app multiple times. The workaroud is to always clean up\n",
        "# the flags before defining them.\n",
        "flags = tf.app.flags\n",
        "del_all_flags(flags.FLAGS, ['logtostderr'])\n",
        "\n",
        "# flags.DEFINE_string('logtostderr', '', '')\n"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SKIPPING exclusion attribute logtostderr\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8oo0ccbl1oMc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "MAKE SURE YOU SET RUNTIME TYPE TO **GPU or TPU**"
      ]
    },
    {
      "metadata": {
        "id": "_zYbFeiXvTgn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "outputId": "3f74bc9d-1a76-44ef-a1e1-75a19083681d"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(f'{DEFAULT_HOME}/models/research')\n",
        "\n",
        "import sys\n",
        "sys.path.append(f'{DEFAULT_HOME}/models/research')\n",
        "sys.path.append(f'{DEFAULT_HOME}/models/research/slim')\n",
        "\n",
        "# Start the training\n",
        "%run object_detection/model_main.py \\\n",
        "     --logtostderr \\\n",
        "     --model_dir=gs://{YOUR_GCS_BUCKET}/model_dir \\\n",
        "     --pipeline_config_path=gs://{YOUR_GCS_BUCKET}/data/faster_rcnn_resnet101_processed.config"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0326 02:30:38.783686 139713059559296 model_lib.py:598] Forced number of epochs for all eval validations to be 1.\n",
            "W0326 02:30:38.785445 139713059559296 model_lib.py:614] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "W0326 02:30:38.788498 139713059559296 estimator.py:1924] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f11026b8730>) includes params argument, but params are not passed to Estimator.\n",
            "W0326 02:30:39.114752 139713059559296 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "W0326 02:30:39.843899 139713059559296 dataset_builder.py:66] num_readers has been reduced to 1 to match input file shards.\n",
            "W0326 02:30:39.854527 139713059559296 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:80: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.parallel_interleave(...)`.\n",
            "W0326 02:30:40.134477 139713059559296 deprecation.py:323] From /content/models/research/object_detection/utils/ops.py:472: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "W0326 02:30:40.207690 139713059559296 deprecation.py:323] From /content/models/research/object_detection/inputs.py:320: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "W0326 02:30:40.934671 139713059559296 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:152: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.batch(..., drop_remainder=True)`.\n",
            "W0326 02:30:48.483517 139713059559296 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/layers.py:1624: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "W0326 02:30:48.560269 139713059559296 deprecation.py:323] From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:2298: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "W0326 02:30:49.479295 139713059559296 variables_helper.py:149] Variable [SecondStageBoxPredictor/BoxEncodingPredictor/biases] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[360]], model variable shape: [[148]]. This variable will not be initialized from the checkpoint.\n",
            "W0326 02:30:49.480808 139713059559296 variables_helper.py:149] Variable [SecondStageBoxPredictor/BoxEncodingPredictor/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[2048, 360]], model variable shape: [[2048, 148]]. This variable will not be initialized from the checkpoint.\n",
            "W0326 02:30:49.486972 139713059559296 variables_helper.py:149] Variable [SecondStageBoxPredictor/ClassPredictor/biases] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[91]], model variable shape: [[38]]. This variable will not be initialized from the checkpoint.\n",
            "W0326 02:30:49.492138 139713059559296 variables_helper.py:149] Variable [SecondStageBoxPredictor/ClassPredictor/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[2048, 91]], model variable shape: [[2048, 38]]. This variable will not be initialized from the checkpoint.\n",
            "W0326 02:30:49.497300 139713059559296 variables_helper.py:152] Variable [global_step] is not available in checkpoint\n",
            "W0326 02:30:53.584252 139713059559296 deprecation.py:323] From /content/models/research/object_detection/core/losses.py:345: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "zzYqu-zRrx7s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Option 1 - Monitor the Cloud ML Training Job in Tensorboard\n",
        "To monitor in the ML Engine dashboard, click on [this link](https://console.cloud.google.com/mlengine/jobs).<br>"
      ]
    },
    {
      "metadata": {
        "id": "XxOT2N3FuDfd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Option 2 - Monitor CoLab Training using Tensorboard running on Colab\n",
        "**OBVIOUSLY YOU CANNOT BOTH TRAIN and MONITOR on COLAB AT THE SAME TIME. ONE SESSION WILL BE STOPED**<br>\n",
        "You will need to install ngrok for tunneling purpose"
      ]
    },
    {
      "metadata": {
        "id": "7x2akQpRuMzW",
        "colab_type": "code",
        "outputId": "c0775438-5b0c-4a1b-9825-99660993eeee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-03-23 20:19:20--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 52.45.248.161, 52.22.145.207, 34.226.180.131, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|52.45.248.161|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13584026 (13M) [application/octet-stream]\n",
            "Saving to: â€˜ngrok-stable-linux-amd64.zipâ€™\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  12.95M  32.9MB/s    in 0.4s    \n",
            "\n",
            "2019-03-23 20:19:21 (32.9 MB/s) - â€˜ngrok-stable-linux-amd64.zipâ€™ saved [13584026/13584026]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dgwKid8quoZq",
        "colab_type": "code",
        "outputId": "ed894d60-e57d-411e-8b18-70f45d5fdf83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "   \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://c2e3a421.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1TIFXPC6ufDG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Start the local Tensorboard with log data feed from your GCS bucket and then **click on the link above**"
      ]
    },
    {
      "metadata": {
        "id": "op17YXMGurh8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "First, we need to do the authorization"
      ]
    },
    {
      "metadata": {
        "id": "YZlBnF4pr1VR",
        "colab_type": "code",
        "outputId": "1ae99e7d-3c09-4276-94b1-4568ced6581d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "cell_type": "code",
      "source": [
        "# This command needs to be run once to allow your local machine to access your\n",
        "# GCS bucket.\n",
        "!gcloud auth application-default login"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "The environment variable [GOOGLE_APPLICATION_CREDENTIALS] is set to:\n",
            "  [/content/adc.json]\n",
            "Credentials will still be generated to the default location:\n",
            "  [/content/.config/application_default_credentials.json]\n",
            "To use these credentials, unset this environment variable before\n",
            "running your application.\n",
            "\n",
            "Do you want to continue (Y/n)?  \n",
            "\n",
            "Go to the following link in your browser:\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&prompt=select_account&response_type=code&client_id=764086051850-6qr4p6gpi6hn506pt8ejuq83di341hur.apps.googleusercontent.com&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform&access_type=offline\n",
            "\n",
            "\n",
            "Enter verification code: 4/EwF9jcyTzUNaKSsCYeYC004t59soSUGh-N_tXuenfdWAr91XFFlUIEQ\n",
            "\n",
            "Credentials saved to file: [/content/.config/application_default_credentials.json]\n",
            "\n",
            "These credentials will be used by any library that requests\n",
            "Application Default Credentials.\n",
            "\n",
            "To generate an access token for other uses, run:\n",
            "  gcloud auth application-default print-access-token\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tASONhN_uxKl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now time to start the **Tensorboard**"
      ]
    },
    {
      "metadata": {
        "id": "dpAeKbUGuikY",
        "colab_type": "code",
        "outputId": "32f2b908-472e-4aaf-bf7f-527696a04387",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "cell_type": "code",
      "source": [
        "!tensorboard --logdir=gs://{YOUR_GCS_BUCKET}/model_dir"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorBoard 1.13.1 at http://66f6bb7f3a12:6006 (Press CTRL+C to quit)\n",
            "W0323 22:35:54.594110 139803632195328 plugin_event_accumulator.py:294] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorboard/plugins/projector/projector_plugin.py:410: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "W0323 22:36:30.326428 139803600250624 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorboard/plugins/projector/projector_plugin.py:410: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "2019-03-23 23:02:30.570712: E tensorflow/core/platform/cloud/curl_http_request.cc:596] The transmission  of request 0x561d07d6f9e0 (URI: https://storage.googleapis.com/id-norm/model_dir%2Fevents.out.tfevents.1553380551.cmle-training-worker-b0b7d51fc4-0-p9qkc) has been stuck at 0 of 0 bytes for 61 seconds and will be aborted. CURL timing information: lookup time: 0.00226 (No error), connect time: 0.002899 (No error), pre-transfer time: 0 (No error), start-transfer time: 0 (No error)\n",
            "2019-03-23 23:02:30.574239: I tensorflow/core/platform/cloud/retrying_utils.cc:73] The operation failed and will be automatically retried in 0.564487 seconds (attempt 1 out of 10), caused by: Unavailable: Error executing an HTTP request: libcurl code 42 meaning 'Operation was aborted by an application callback', error details: Callback aborted\n",
            "\t when reading gs://id-norm/model_dir/events.out.tfevents.1553380551.cmle-training-worker-b0b7d51fc4-0-p9qkc\n",
            "2019-03-24 00:01:33.626559: E tensorflow/core/platform/cloud/curl_http_request.cc:596] The transmission  of request 0x561d085d72a0 (URI: https://www.googleapis.com/storage/v1/b/id-norm/o?fields=items%2Fname%2CnextPageToken&prefix=model_dir%2F) has been stuck at 0 of 0 bytes for 61 seconds and will be aborted. CURL timing information: lookup time: 0.002658 (No error), connect time: 0.003526 (No error), pre-transfer time: 0 (No error), start-transfer time: 0 (No error)\n",
            "2019-03-24 00:01:33.630115: I tensorflow/core/platform/cloud/retrying_utils.cc:73] The operation failed and will be automatically retried in 0.984554 seconds (attempt 1 out of 10), caused by: Unavailable: Error executing an HTTP request: libcurl code 42 meaning 'Operation was aborted by an application callback', error details: Callback aborted\n",
            "\t when reading gs://id-norm/model_dir\n",
            "2019-03-24 00:29:14.823664: E tensorflow/core/platform/cloud/curl_http_request.cc:596] The transmission  of request 0x561d085d72a0 (URI: https://www.googleapis.com/storage/v1/b/id-norm/o?fields=items%2Fname%2CnextPageToken&prefix=model_dir%2F) has been stuck at 0 of 0 bytes for 61 seconds and will be aborted. CURL timing information: lookup time: 0.002528 (No error), connect time: 0.003595 (No error), pre-transfer time: 0 (No error), start-transfer time: 0 (No error)\n",
            "2019-03-24 00:29:14.827208: I tensorflow/core/platform/cloud/retrying_utils.cc:73] The operation failed and will be automatically retried in 0.407639 seconds (attempt 1 out of 10), caused by: Unavailable: Error executing an HTTP request: libcurl code 42 meaning 'Operation was aborted by an application callback', error details: Callback aborted\n",
            "\t when reading gs://id-norm/model_dir\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GVxZLrhisIzP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JFTt3jB805Cq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Option 3 - Monitor CoLab Training Job on Google Cloud Shell\n",
        "* Log into the Google Cloud and run cloud shell\n",
        "* In the shell run\n",
        "```\n",
        "export YOUR_GCS_BUCKET='id-norm'\n",
        "tensorboard --logdir=gs://$YOUR_GCS_BUCKET/model_dir\n",
        "```\n"
      ]
    },
    {
      "metadata": {
        "id": "wE6TqxD-1TUR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}